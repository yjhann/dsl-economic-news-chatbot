import sys
import streamlit as st
import pandas as pd
import random
from langchain_community.chat_models import ChatOpenAI
import subprocess

import os
from dotenv import load_dotenv
load_dotenv()

from openai import OpenAI
client = OpenAI()

# âœ… í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ëª¨ë“ˆ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# âœ… ëª¨ë“ˆ import
import news_summarizer
import economic_terms_RAG as term_explainer
import ner  
import ner_similarity_chatbot2 as ner_similarity
import company_info  
import news_recommender_final2 as news_recommender
import generate_quiz_module
import qa_prompt_module 

from news_summarizer import summarize_news
from ner import extract_ner_from_text 
from ner_similarity_chatbot2 import generate_weighted_query, find_similar_news 
from news_recommender_final2 import load_news_data, load_embeddings_and_index, recommend_similar_news
from generate_quiz_module import generate_quiz 

print("âœ… chatbot.py ì‹¤í–‰ë¨!")

# âœ… ë°ì´í„° ë¡œë“œ
csv_file_path = "ë‰´ìŠ¤ê¸°ì‚¬_ìµœì¢….csv"
df_news = pd.read_csv(csv_file_path)

# âœ… FAISS ë° ë²¡í„° ì´ˆê¸°í™” (ì‚¬ê±´ ê¸°ë°˜ ì¶”ì²œìš©)
if "recommender_initialized" not in st.session_state:
    embedding_path = "news_embeddings.npy"
    id_path = "news_ids.npy"
    index_path = "news_faiss.index"

    news_recommender.load_news_data(csv_file_path)
    news_recommender.load_embeddings_and_index(embedding_path, id_path, index_path)

    st.session_state.recommender_initialized = True

# âœ… Streamlit UI ì‹œì‘
st.title("ğŸ“° ê¸ˆë¦°ì´ë¥¼ ìœ„í•œ ê²½ì œ ë‰´ìŠ¤ ë¦¬ë”©ë©”ì´íŠ¸")

# 1ï¸âƒ£ ì‚¬ìš©ìê°€ ê²½ì œ ì¹´í…Œê³ ë¦¬ ì„ íƒ (ì„ íƒ ì—†ìŒ ì¶”ê°€)
categories = ["ì„ íƒ ì—†ìŒ", "ê¸ˆìœµ", "ì¦ê¶Œ", "ì‚°ì—…ì¬ê³„", "ì¤‘ê¸°ë²¤ì²˜", "ë¶€ë™ì‚°", "ê¸€ë¡œë²Œê²½ì œ", "ìƒí™œê²½ì œ", "ê²½ì œì¼ë°˜"]
selected_category = st.selectbox("ğŸ“Œ ê´€ì‹¬ ìˆëŠ” ê²½ì œ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”!", categories, index=0)

# âœ… ì„¸ì…˜ ì´ˆê¸°í™” (ì²« ì‹¤í–‰ ì‹œ)
if "random_articles" not in st.session_state:
    st.session_state.random_articles = None
if "selected_news" not in st.session_state:
    st.session_state.selected_news = None
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []  # ëŒ€í™” ê¸°ë¡ ì €ì¥

# âœ… 2ï¸âƒ£ ì˜¬ë°”ë¥¸ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì•¼ ì§„í–‰ ê°€ëŠ¥
if selected_category == "ì„ íƒ ì—†ìŒ":
    st.warning("âš ï¸ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”!")
    st.stop()

filtered_news = df_news[df_news["category"] == selected_category]

# âœ… 3ï¸âƒ£ í—¤ë“œë¼ì¸ ëœë¤ ì„ íƒ 
if "selected_category" not in st.session_state or st.session_state.selected_category != selected_category:
    st.session_state.selected_category = selected_category
    st.session_state.random_articles = filtered_news.sample(n=3) if not filtered_news.empty else None

    # ë°˜ë“œì‹œ ì´ì „ ìƒíƒœ ì´ˆê¸°í™”
    for key in ["selected_news", "last_processed_news", "summary", "economic_terms", "ner_results", "chat_history", "quiz_text"]:
        st.session_state.pop(key, None)


# âœ… 4ï¸âƒ£ ì‚¬ìš©ìê°€ í—¤ë“œë¼ì¸ ì„ íƒ
if st.session_state.random_articles is not None:
    st.write("ğŸ” ê´€ì‹¬ ìˆëŠ” ë‰´ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    options = [f"{i+1}. {headline}" for i, headline in enumerate(st.session_state.random_articles["headline"])]
    selected_news = st.radio("ë‰´ìŠ¤ ì„ íƒ", options)

    if selected_news:
        selected_index = options.index(selected_news)
        new_selected = st.session_state.random_articles.iloc[selected_index].to_dict()

        # ìƒˆ ë‰´ìŠ¤ê°€ ê¸°ì¡´ê³¼ ë‹¤ë¥´ë©´ ìƒíƒœ ì´ˆê¸°í™”
        if st.session_state.get("selected_news") != new_selected:
            st.session_state.selected_news = new_selected
            for key in ["summary", "economic_terms", "ner_results", "chat_history", "quiz_text"]:
                st.session_state.pop(key, None)
            st.session_state.last_processed_news = new_selected


# âœ… 5ï¸âƒ£ ë‰´ìŠ¤ ì •ë³´ ì¶œë ¥ (ì„ íƒí•œ ë‰´ìŠ¤ ìœ ì§€)
if st.session_state.selected_news is not None:
    news_item = st.session_state.selected_news

    st.subheader("ğŸ“Œ ì„ íƒí•œ ë‰´ìŠ¤")
    st.write(f"**ğŸ“° í—¤ë“œë¼ì¸:** {news_item['headline']}")
    st.write(f"ğŸ”— [ì›ë¬¸ ë³´ê¸°]({news_item['link']})")

    # âœ… 6ï¸âƒ£ ë‰´ìŠ¤ ë³¸ë¬¸ ìš”ì•½ (í•œ ë²ˆë§Œ ì‹¤í–‰)
    if "summary" not in st.session_state or st.session_state.selected_news["headline"] != news_item["headline"]:
        st.session_state.summary = summarize_news(news_item["content"])

    st.subheader("ğŸ“Œ ë‰´ìŠ¤ ìš”ì•½")
    st.write(st.session_state.summary)

    # âœ… ê²½ì œ ìš©ì–´ ì„¤ëª… (í•œ ë²ˆë§Œ ì‹¤í–‰)
    if "economic_terms" not in st.session_state or st.session_state.selected_news["headline"] != news_item["headline"]:
        st.session_state.economic_terms = term_explainer.extract_financial_terms(news_item["content"])

    st.subheader("ğŸ“Œ ê²½ì œ ìš©ì–´ ì„¤ëª…")
    for term in st.session_state.economic_terms:
        explanation, related_terms = term_explainer.recommend_similar_words(term)
        st.write(f"ğŸ“– **{term}**: {explanation}")

        if related_terms:
            related_str = ", ".join(related_terms)
            st.write(f"ğŸ”— **ì—°ê´€ ìš©ì–´**: {related_str}")

    # # âœ… 8ï¸âƒ£ Named Entity Recognition (NER) ì ìš©
    # st.subheader("ğŸ“Œ Named Entity Recognition (NER) ê²°ê³¼")

    # âœ… NER ë¶„ì„ì„ í•œ ë²ˆë§Œ ì‹¤í–‰í•˜ë„ë¡ session_state í™œìš©
    if "ner_results" not in st.session_state or st.session_state.selected_news != news_item:
        selected_news_content = news_item["content"]
    
        # âœ… NERì„ ì‚¬ìš©í•˜ì—¬ ê¸°ì—…ëª… ì¶”ì¶œ
        company_ner, _ = extract_ner_from_text(selected_news_content)

        if company_ner:
            from collections import Counter

            # âœ… ê¸°ì—…ë³„ ë“±ì¥ íšŸìˆ˜ ê³„ì‚°
            company_counts = Counter(company_ner)
            top_companies = company_counts.most_common(5)  # ìƒìœ„ 5ê°œ ê¸°ì—…

            # âœ… ìƒìœ„ 2ê°œì˜ ê¸°ì—…ë§Œ ì„ íƒ
            top_2_companies = top_companies[:2]

            # âœ… GPTì— ì „ë‹¬í•  ê¸°ì—… ì„¤ëª…ìš© ë¬¸ìì—´ ìƒì„±
            formatted_companies = "\n".join([f"- {company}: {count}íšŒ" for company, count in top_2_companies])

            # âœ… GPTë¥¼ í™œìš©í•˜ì—¬ ìƒìœ„ 2ê°œ ê¸°ì—… ì„¤ëª… ìƒì„±
            company_descriptions = company_info.get_company_info(formatted_companies)

            # âœ… ê²°ê³¼ë¥¼ session_stateì— ì €ì¥ (í•œ ë²ˆë§Œ ì‹¤í–‰)
            st.session_state.ner_results = {"top_companies": top_2_companies, "descriptions": company_descriptions}
        else:
            st.session_state.ner_results = {"top_companies": [], "descriptions": "ğŸš¨ NER ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‰´ìŠ¤ ë³¸ë¬¸ì—ì„œ ê¸°ì—…ëª…ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}

    # âœ… ì €ì¥ëœ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°
    ner_results = st.session_state.ner_results
    top_2_companies = ner_results["top_companies"]
    company_descriptions = ner_results["descriptions"]

    # # âœ… ê²°ê³¼ ì¶œë ¥
    # if top_2_companies:
    #     for company, count in top_2_companies:
    #         st.write(f"ğŸ”¹ **{company}** ({count}íšŒ ë“±ì¥)")

    st.subheader("ğŸ“Œ ê¸°ì—… ì„¤ëª…")
    st.write(company_descriptions)

    # # âœ… 9ï¸âƒ£ ì¶”ê°€ ì§ˆë¬¸ ë°›ê¸° (ëŒ€í™” íˆìŠ¤í† ë¦¬ ìœ ì§€)    
    with st.expander("ğŸ’¬ ì¶”ê°€ ì§ˆë¬¸í•˜ê¸°"):
        user_question = st.text_input("ë‰´ìŠ¤ì™€ ê´€ë ¨í•˜ì—¬ ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•˜ì„¸ìš”:")

        if st.button("ì§ˆë¬¸í•˜ê¸°") and user_question:
        # âœ… ê²½ì œ ìš©ì–´ dict êµ¬ì„±
            term_expl_dict = {
                term: term_explainer.recommend_similar_words(term)  # (ì„¤ëª…, ì—°ê´€ìš©ì–´)
                for term in st.session_state.economic_terms
            }

            # âœ… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = qa_prompt_module.build_prompt(
                category=selected_category,
                news_content=news_item["content"],
                summary=st.session_state.summary,
                term_explanations=term_expl_dict,
                company_info=company_descriptions,
                user_question=user_question
            )

            # âœ… GPT í˜¸ì¶œ
            completion = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}]
            )
            response = completion.choices[0].message.content.strip()

            # âœ… ëŒ€í™” ê¸°ë¡ ì €ì¥
            st.session_state.chat_history.append({"question": user_question, "answer": response})

    # âœ… ğŸ”Ÿ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶œë ¥ (ê¸°ì¡´ ì§ˆë¬¸+ë‹µë³€ ìœ ì§€)
    if "chat_history" in st.session_state and st.session_state.chat_history:
        st.subheader("ğŸ—‚ï¸ ëŒ€í™” ê¸°ë¡")
        for chat in st.session_state.chat_history:
            st.write(f"**â“ ì§ˆë¬¸:** {chat['question']}")
            st.write(f"**ğŸ’¡ ë‹µë³€:** {chat['answer']}")
            st.write("---")
    
    # âœ… ğŸ”Ÿ ìœ ì‚¬ ë‰´ìŠ¤ ì¶”ì²œ
    if st.button("ì§ˆë¬¸ ë§ˆì¹˜ê¸°"):
        st.subheader("ğŸ” ìœ ì‚¬í•œ ë‰´ìŠ¤ ì¶”ì²œ")

        # âœ… NER ê¸°ë°˜ ì¶”ì²œ
        st.subheader("ğŸ“Œ NER ê¸°ë°˜ ì¶”ì²œ") 
        top_2_company_names = [name for name, count in top_2_companies]
        query = generate_weighted_query(news_item["content"], top_2_company_names)
        print(query)
        recommended_news = find_similar_news(query)
        for idx, news in enumerate(recommended_news, 1):
            st.write(f"**{idx}. {news['headline']}**")
            st.write(f"ğŸ”— [ì›ë¬¸ ë³´ê¸°]({news['link']})")

        # âœ… ì‚¬ê±´ ê¸°ë°˜ ì¶”ì²œ
        st.subheader("ğŸ“Œ ì‚¬ê±´ ê¸°ë°˜ ì¶”ì²œ")

        news_title = news_item["headline"]
        news_content = news_item["content"]  # content ê¸°ì¤€ ë²„ì „ì´ë¼ë©´ contentë¥¼ ë„£ì–´ì•¼ í•¨

        try:
            similar_news = recommend_similar_news(news_title, news_content, top_n=4)
            for idx, row in similar_news.iterrows():
                st.write(f"**{row['headline']}**")
                st.write(f"ğŸ”— [ì›ë¬¸ ë³´ê¸°]({row['link']})")
        except Exception as e:
            st.error(f"âŒ ìœ ì‚¬ ë‰´ìŠ¤ ì¶”ì²œ ì‹¤íŒ¨: {e}")
        
        # âœ… í€´ì¦ˆ ìƒì„±
        st.markdown("---")
        st.subheader("ğŸ§  ë‰´ìŠ¤ ê¸°ë°˜ ê²½ì œ í€´ì¦ˆ í’€ê¸°")
        if "selected_news" in st.session_state:
            news_item = st.session_state.selected_news
            summary = st.session_state.summary
            company_info = st.session_state.ner_results["descriptions"]
            content = news_item["content"]

            # í€´ì¦ˆ ìë™ ìƒì„± ë° ì €ì¥
            with st.spinner("GPTê°€ í€´ì¦ˆë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    quiz_text = generate_quiz(st.session_state, client)
                    st.session_state.quiz_text = quiz_text
                except Exception as e:
                    st.error(f"âŒ í€´ì¦ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


            # í€´ì¦ˆ ì¶œë ¥
            if "quiz_text" in st.session_state:
                st.subheader("ğŸ§ª í€´ì¦ˆ ë¬¸ì œ")

                quiz_blocks = st.session_state.quiz_text.strip().split("\n\n")
                for block in quiz_blocks:
                    lines = block.strip().split("\n")
                    if not lines or len(lines) < 3:
                        continue

                    question = lines[0]
                    options = [line for line in lines[1:] if line.startswith("â‘ ") or line.startswith("â‘¡") or line.startswith("â‘¢") or line.startswith("â‘£")]
                    answer_line = next((line for line in lines if line.startswith("ì •ë‹µ")), None)
                    explanation_line = next((line for line in lines if line.startswith("í•´ì„¤")), None)

                    with st.container():
                        st.markdown(f"**{question}**")
                        for opt in options:
                            st.markdown(f"- {opt}")
                        if answer_line:
                            st.success(answer_line)
                        if explanation_line:
                            st.info(explanation_line)
        else:
            st.warning("ë‰´ìŠ¤ë¥¼ ë¨¼ì € ì„ íƒí•˜ê³  ìš”ì•½, ê¸°ì—… ì„¤ëª…ì„ ì§„í–‰í•´ì£¼ì„¸ìš”.")


